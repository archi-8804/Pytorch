{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e31c35",
   "metadata": {},
   "source": [
    "# Digit Classification on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600a449",
   "metadata": {},
   "source": [
    "MNIST\n",
    "\n",
    "DataLoader, Transformation\n",
    "\n",
    "MultiLayer Neural Net, activation function\n",
    "\n",
    "Loss and Optimizer\n",
    "\n",
    "Training Loop(batch training)\n",
    "\n",
    "Model evaluation\n",
    "\n",
    "GPU Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095874a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f5b8b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device config\n",
    "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2426c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter\n",
    "input_size=784  #28x28\n",
    "hidden_size=100\n",
    "num_classes=10\n",
    "num_epochs=2\n",
    "batch_size=100\n",
    "leaning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d165a210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:13<00:00, 746015.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 3575855.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:02<00:00, 646007.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 3306235.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#MNIST Data\n",
    "train_dataset=torchvision.datasets.MNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
    "\n",
    "test_dataset=torchvision.datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93790275",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader= torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d68204af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "examples=iter(train_loader)\n",
    "samples, labels=examples.__next__() \n",
    "print(samples.shape,labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc05fdcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(samples[i][0],cmap='gray')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0495f1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_of_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1=nn.Linear(input_size, hidden_size)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.l2=nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.l1(x)\n",
    "        out=self.relu(out)\n",
    "        out=self.l2(out)\n",
    "        return out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85f7261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=NeuralNet(input_size,hidden_size,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d49259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss and optimizer\n",
    "learning_rate=0.01\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ad216e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m labels\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#forward\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m outputs\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m loss\u001b[38;5;241m=\u001b[39mcriterion(outputs, labels)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#backwards\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m, in \u001b[0;36mNeuralNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m----> 9\u001b[0m     out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m     11\u001b[0m     out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml2(out)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "n_total_steps=len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        #shape of image 100,1,28,28\n",
    "        #100,784\n",
    "        #reshape tensor\n",
    "        images=images.reshape(-1,28*28).to(device)\n",
    "        labels=labels.to(device)\n",
    "        \n",
    "        #forward\n",
    "        outputs=model(images)\n",
    "        loss=criterion(outputs, labels)\n",
    "        \n",
    "        #backwards\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i+1)%100==0:\n",
    "            print(f'{epoch+1}/{num_epochs},step {i+1}/{n_total_steps},loss={loss.item():.4f}')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "821ceacd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m images\u001b[38;5;241m=\u001b[39mimages\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m labels\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 8\u001b[0m outputs\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#value, index\u001b[39;00m\n\u001b[0;32m     10\u001b[0m _, predictions \u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmax(outputs,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m, in \u001b[0;36mNeuralNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m----> 9\u001b[0m     out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m     11\u001b[0m     out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml2(out)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "#test\n",
    "with torch.no_grad():\n",
    "    n_correct=0\n",
    "    n_samples=0\n",
    "    for images, labels in test_loader:\n",
    "        images=images.reshape(-1,28*28).to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs=model(images)\n",
    "        #value, index\n",
    "        _, predictions =torch.max(outputs,1)\n",
    "        n_samples += lapels.shape[0]\n",
    "        n_correct = (predictions == labels).sum().item()\n",
    "        \n",
    "    acc-100*n_correct/n_samples\n",
    "    print(f'accuracy={acc}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b7bcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
